import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from utils.utils import save_checkpoint, load_checkpoint

def train_pix2pix(generator, discriminator, dataloader, num_epochs=100, lr=2e-4, lambda_l1=100, device="cuda"):
    # Optimizers for generator and discriminator
    opt_gen = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
    opt_disc = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

    # Loss functions
    criterion_gan = nn.BCELoss()  # Binary Cross-Entropy for GAN loss
    criterion_l1 = nn.L1Loss()    # L1 loss for pixel-wise similarity

    for epoch in range(num_epochs):
        loop = tqdm(dataloader, leave=True)
        for idx, (edges, reals) in enumerate(loop):
            edges, reals = edges.to(device), reals.to(device)

            ### Update Discriminator ###
            discriminator.train()
            generator.eval()

            # Real images (ground truth images)
            preds_real = discriminator(reals)
            # Dynamically create the real labels based on the size of preds_real
            real_label = torch.ones_like(preds_real, device=device)
            loss_disc_real = criterion_gan(preds_real, real_label)

            # Fake images (generated by generator from edge images)
            fakes = generator(edges)
            preds_fake = discriminator(fakes)
            # Dynamically create the fake labels based on the size of preds_fake
            fake_label = torch.zeros_like(preds_fake, device=device)
            loss_disc_fake = criterion_gan(preds_fake, fake_label)

            # Total discriminator loss
            loss_disc = (loss_disc_real + loss_disc_fake) / 2

            # Backprop and optimize discriminator
            opt_disc.zero_grad()
            loss_disc.backward()
            opt_disc.step()

            ### Update Generator ###
            generator.train()
            discriminator.eval()

            # Generator loss: GAN loss + L1 loss
            fakes = generator(edges)
            preds_fake = discriminator(fakes)
            loss_gan = criterion_gan(preds_fake, real_label)  # Try to fool the discriminator

            loss_l1 = criterion_l1(fakes, reals) * lambda_l1  # L1 loss

            # Total generator loss
            loss_gen = loss_gan + loss_l1

            # Backprop and optimize generator
            opt_gen.zero_grad()
            loss_gen.backward()
            opt_gen.step()

            # Update progress bar
            loop.set_description(f"Epoch [{epoch+1}/{num_epochs}]")
            loop.set_postfix(loss_gen=loss_gen.item(), loss_disc=loss_disc.item())

        # Optionally save model checkpoints
        if (epoch + 1) % 5 == 0:
            save_checkpoint({
                'epoch': epoch + 1,
                'generator_state_dict': generator.state_dict(),
                'discriminator_state_dict': discriminator.state_dict(),
                'opt_gen_state_dict': opt_gen.state_dict(),
                'opt_disc_state_dict': opt_disc.state_dict(),
            }, filename=f"pix2pix_checkpoint_epoch_{epoch+1}.pth.tar")

# def train_model(generator, discriminator, train_loader, num_epochs=100, device='cuda'):
#     adversarial_loss = nn.BCELoss().to(device)
#     optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))
#     optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))

#     for epoch in range(num_epochs):
#         for i, (real_images, _) in enumerate(train_loader):
#             # Move real images to the device
#             real_images = real_images.to(device)
#             batch_size = real_images.size(0)
            
#             # Labels for real and fake images
#             valid = torch.ones(batch_size, 1, requires_grad=False).to(device)
#             fake = torch.zeros(batch_size, 1, requires_grad=False).to(device)

#             # ---------------------
#             #  Train Discriminator
#             # ---------------------
#             optimizer_D.zero_grad()

#             # Generate fake images
#             noise = torch.randn(batch_size, 3, 256, 256).to(device)
#             fake_images = generator(noise)

#             # Discriminator loss for real and fake images
#             real_loss = adversarial_loss(discriminator(real_images), valid)
#             fake_loss = adversarial_loss(discriminator(fake_images.detach()), fake)
#             d_loss = (real_loss + fake_loss) / 2

#             # Backpropagation and optimization step for the discriminator
#             d_loss.backward()
#             optimizer_D.step()

#             # -----------------
#             #  Train Generator
#             # -----------------
#             optimizer_G.zero_grad()

#             # Generator loss: try to fool the discriminator
#             g_loss = adversarial_loss(discriminator(fake_images), valid)

#             # Backpropagation and optimization step for the generator
#             g_loss.backward()
#             optimizer_G.step()

#             # Print progress (optional, for debugging)
#             if i % 100 == 0:
#                 print(f"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(train_loader)}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]")

#         # Save model weights after each epoch
#         torch.save(generator.state_dict(), f'generator_epoch_{epoch+1}.pth')
#         torch.save(discriminator.state_dict(), f'discriminator_epoch_{epoch+1}.pth')

#     # Optionally return the trained models
#     return generator, discriminator
