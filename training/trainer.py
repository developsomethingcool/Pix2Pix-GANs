import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from utils.utils import save_checkpoint, load_checkpoint

def train_pix2pix(generator, discriminator, dataloader, opt_gen, opt_disc, num_epochs=100, start_epoch=1, lr=2e-4, lambda_l1=100, device="cuda"):
    # Optimizers for generator and discriminator
    #opt_gen = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
    #opt_disc = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

    # Loss functions
    criterion_gan = nn.BCELoss()  # Binary Cross-Entropy for GAN loss
    criterion_l1 = nn.L1Loss()    # L1 loss for pixel-wise similarity

    for epoch in range(start_epoch, num_epochs+1):
        loop = tqdm(dataloader, leave=True)
        for idx, (edges, reals) in enumerate(loop):
            edges, reals = edges.to(device), reals.to(device)

            ### Update Discriminator ###
            discriminator.train()
            generator.eval()

            # Real images (ground truth images)
            preds_real = discriminator(reals)
            # Dynamically create the real labels based on the size of preds_real
            real_label = torch.ones_like(preds_real, device=device)
            loss_disc_real = criterion_gan(preds_real, real_label)

            # Fake images (generated by generator from edge images)
            fakes = generator(edges)
            preds_fake = discriminator(fakes)
            # Dynamically create the fake labels based on the size of preds_fake
            fake_label = torch.zeros_like(preds_fake, device=device)
            loss_disc_fake = criterion_gan(preds_fake, fake_label)

            # Total discriminator loss
            loss_disc = (loss_disc_real + loss_disc_fake) / 2

            # Backprop and optimize discriminator
            opt_disc.zero_grad()
            loss_disc.backward()
            opt_disc.step()

            ### Update Generator ###
            generator.train()
            discriminator.eval()

            # Generator loss: GAN loss + L1 loss
            fakes = generator(edges)
            preds_fake = discriminator(fakes)
            loss_gan = criterion_gan(preds_fake, real_label)  # Try to fool the discriminator

            loss_l1 = criterion_l1(fakes, reals) * lambda_l1  # L1 loss

            # Total generator loss
            loss_gen = loss_gan + loss_l1

            # Backprop and optimize generator
            opt_gen.zero_grad()
            loss_gen.backward()
            opt_gen.step()

            # Update progress bar
            loop.set_description(f"Epoch [{epoch+1}/{num_epochs}]")
            loop.set_postfix(loss_gen=loss_gen.item(), loss_disc=loss_disc.item())

            # Save checkpoint
            if (epoch) % 10 == 0:
                save_checkpoint({
                    'epoch': epoch,
                    'generator_state_dict': generator.state_dict(),
                    'discriminator_state_dict': discriminator.state_dict(),
                    'opt_gen_state_dict': opt_gen.state_dict(),
                    'opt_disc_state_dict': opt_disc.state_dict(),
                }, filename=f"pix2pix_checkpoint_epoch_{epoch}.pth.tar")